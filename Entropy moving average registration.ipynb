{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65b8d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 18:01:24.797528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/shantanu.singh/miniconda3/envs/py37/lib\n",
      "2022-02-25 18:01:24.797568: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import quaternion\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a317cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /scratch/shantanu/results_23022022/occant_rgb/dump/0/Cantwell/front/bev_pred\n",
    "# !ls /scratch/shantanu/gibson4/new/Cantwell/0/front/pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d7ebb896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta : momentum for moving average update\n",
    "beta = 0.99##\n",
    "threshold_explored = 0.5 ##\n",
    "threshold_entropy = 0.5 ##\n",
    "EPS_MAPPER = 1e-6\n",
    "s = 0.05\n",
    "LOCAL_MAP_SIZE = 128##\n",
    "OUTMAP_SIZE = 1024##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d733c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(m,p_reg):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        m - ( 2, M, M) - global map\n",
    "        p_reg - ( 2, M, M) - registered egomap\n",
    "    \"\"\"\n",
    "#     explored_mask = (p_reg[:, 1] > threshold_explored).float()\n",
    "    explored_mask = (p_reg[1] > threshold_explored)\n",
    "    '''\n",
    "    Looks like they want sone kind of count on \n",
    "    number of observations for that cell\n",
    "    '''\n",
    "    \n",
    "    log_p_reg = np.log(p_reg + EPS_MAPPER)\n",
    "    log_1_p_reg = np.log(1 - p_reg + EPS_MAPPER)\n",
    "#     log_p_reg = torch.log(p_reg + EPS_MAPPER)\n",
    "#     log_1_p_reg = torch.log(1 - p_reg + EPS_MAPPER)\n",
    "    entropy = -p_reg * log_p_reg - (1 - p_reg) * log_1_p_reg\n",
    "#     print(\"Entropy shape : \",entropy.shape)\n",
    "#     entropy_mask = (entropy.mean(dim=1) < threshold_entropy).float()\n",
    "    '''\n",
    "    Entroypy mask mean along ???\n",
    "    '''\n",
    "    entropy_mask = (entropy.mean(axis=0) < threshold_entropy)\n",
    "    \n",
    "    explored_mask = explored_mask * entropy_mask\n",
    "#     unfilled_mask = (m[:, 1] == 0).float()\n",
    "    unfilled_mask = (m[1] == 0)\n",
    "    \n",
    "    m_updated = m\n",
    "    # For regions that are unfilled, write as it is\n",
    "    mask = unfilled_mask * explored_mask\n",
    "#     mask = mask.unsqueeze(1)\n",
    "    m_updated = m_updated * (1 - mask) + p_reg * mask\n",
    "    # For regions that are filled, do a moving average\n",
    "    mask = (1 - unfilled_mask) * explored_mask\n",
    "#     mask = mask.unsqueeze(1)\n",
    "    p_reg_ma = (p_reg * (1 - beta) + m_updated * beta) * mask\n",
    "    m_updated = m_updated * (1 - mask) + p_reg_ma * mask\n",
    "    \n",
    "    return m_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4988c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_transform_map(p, x, invert=True, mode=\"linear\"):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        p     - ( f, H, W) Tensor\n",
    "        x     - (3) Tensor (x, y, theta) transforms to perform\n",
    "    Outputs:\n",
    "        p_trans - (bs, f, H, W) Tensor\n",
    "    Conventions:\n",
    "        Shift in X is rightward, and shift in Y is downward. Rotation is clockwise.\n",
    "    Note: These denote transforms in an agent's position. Not the image directly.\n",
    "    For example, if an agent is moving upward, then the map will be moving downward.\n",
    "    To disable this behavior, set invert=False.\n",
    "    \"\"\"\n",
    "#     device = p.device\n",
    "#     H, W = p.shape[2:]\n",
    "    H, W = p.shape[1:]\n",
    "    \n",
    "#     trans_x = x[:, 0]\n",
    "#     trans_y = x[:, 1]\n",
    "    trans_x = x[0]\n",
    "    trans_y = x[1]\n",
    "    # Convert translations to -1.0 to 1.0 range\n",
    "    Hby2 = (H - 1) / 2 if H % 2 == 1 else H / 2\n",
    "    Wby2 = (W - 1) / 2 if W % 2 == 1 else W / 2\n",
    "\n",
    "    trans_x = trans_x / Wby2\n",
    "    trans_y = trans_y / Hby2\n",
    "#     rot_t = x[:, 2]\n",
    "    rot_t = x[2]\n",
    "\n",
    "#     sin_t = torch.sin(rot_t)\n",
    "#     cos_t = torch.cos(rot_t)\n",
    "    sin_t = np.sin(rot_t)\n",
    "    cos_t = np.cos(rot_t)\n",
    "    # This R convention means Y axis is downwards.\n",
    "#     A = np.zeros((p.size(0), 3, 3)).to(device)\n",
    "#     A = np.zeros((p.shape[0], 3, 3))\n",
    "    A = np.zeros((3, 3))\n",
    "    \n",
    "#     A[:, 0, 0] = cos_t\n",
    "#     A[:, 0, 1] = -sin_t\n",
    "#     A[:, 1, 0] = sin_t\n",
    "#     A[:, 1, 1] = cos_t\n",
    "#     A[:, 0, 2] = trans_x\n",
    "#     A[:, 1, 2] = trans_y\n",
    "#     A[:, 2, 2] = 1\n",
    "    A[0, 0] = cos_t\n",
    "    A[0, 1] = -sin_t\n",
    "    A[1, 0] = sin_t\n",
    "    A[1, 1] = cos_t\n",
    "    A[0, 2] = trans_x\n",
    "    A[1, 2] = trans_y\n",
    "    A[2, 2] = 1\n",
    "    # Since this is a source to target mapping, and F.affine_grid expects\n",
    "    # target to source mapping, we have to invert this for normal behavior.\n",
    "#     Ainv = torch.inverse(A)\n",
    "    Ainv = np.linalg.inv(A)\n",
    "    print(A)\n",
    "    print(np.round(Ainv,2))\n",
    "\n",
    "    # If target to source mapping is required, invert is enabled and we invert\n",
    "    # it again.\n",
    "    if invert:\n",
    "#         Ainv = torch.inverse(Ainv)\n",
    "        Ainv = np.linalg.inv(Ainv)\n",
    "        \n",
    "#     Ainv = Ainv[:, :2]\n",
    "#     Ainv = Ainv[:2]\n",
    "#     print(Ainv)\n",
    "#     print(p.shape,Ainv.shape)\n",
    "#     p_trans = cv2.warpAffine(p[0],Ainv[:-1,:],(1024,1024))\n",
    "    p_trans = scipy.ndimage.affine_transform(p,Ainv)\n",
    "#     print(p_trans.shape)\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(p[0])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(p_trans[0])\n",
    "#     grid = F.affine_grid(Ainv, p.size())\n",
    "#     print(np.unique(p))\n",
    "#     plt.\n",
    "#     p_trans = F.grid_sample(p, grid, mode=mode)\n",
    "    '''\n",
    "    Initially it was mode=\"bilinear \" but in scipy.interpolate.griddata ,\n",
    "    no such mode is present. So i set the default to \"linear\"\n",
    "    '''\n",
    "#     p_trans = scipy.interpolate.griddata(p, grid, mode=mode)\n",
    "\n",
    "    return p_trans\n",
    "\n",
    "def spatial_transform(p, dx, invert=False):\n",
    "    # Convert dx to map image coordinate system with X as rightward and Y as downward\n",
    "#     dx_map = torch.stack(\n",
    "#         [(dx[:, 1] / s), -(dx[:, 0] / s), dx[:, 2]], dim=1\n",
    "#     )  # anti-clockwise rotation\n",
    "#     dx_map = np.stack(\n",
    "#         [(dx[:, 1] / s), -(dx[:, 0] / s), dx[:, 2]], axis=1\n",
    "#     )\n",
    "    dx_map = np.stack(\n",
    "        [(dx[1] / s), -(dx[0] / s), dx[2]]\n",
    "    )\n",
    "#     print(dx_map)\n",
    "    p_trans = spatial_transform_map(p, dx_map, invert=invert)\n",
    "\n",
    "    return p_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0065dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_map(m,p,x):\n",
    "    \"\"\"\n",
    "    Given the locally computed map, register it to the global map based\n",
    "    on the current position.\n",
    "    Inputs:\n",
    "    m - ( F, M, M) global map\n",
    "    p - ( F, V, V) local map\n",
    "    x - ( 3) in global coordinates\n",
    "    \"\"\"\n",
    "    V = LOCAL_MAP_SIZE\n",
    "    M = m.shape[2]\n",
    "    Vby2 = (V - 1) // 2 if V % 2 == 1 else V // 2\n",
    "    Mby2 = (M - 1) // 2 if M % 2 == 1 else M // 2\n",
    "    # The agent stands at the bottom-center of the egomap and looks upward\n",
    "    left_h_pad = Mby2 - V + 1\n",
    "    right_h_pad = M - V - left_h_pad\n",
    "    left_w_pad = Mby2 - Vby2\n",
    "    right_w_pad = M - V - left_w_pad\n",
    "    # Add zero padding to p so that it matches size of global map\n",
    "#     print(p.shape)\n",
    "    p_pad = np.zeros((p.shape[0],M,M))\n",
    "    p_pad[:,left_h_pad:left_h_pad+V,left_w_pad:left_w_pad+V] = p\n",
    "#     print(p_pad.shape)\n",
    "\n",
    "#     p_pad = F.pad(\n",
    "#             p, (left_w_pad, right_w_pad, left_h_pad, right_h_pad), \"constant\", value=0\n",
    "#         )\n",
    "#     p_pad = np.pad(\n",
    "#     p, np.array([(left_w_pad, right_w_pad, left_h_pad, right_h_pad),(left_w_pad, right_w_pad, left_h_pad, right_h_pad)]).T, \"constant\")\n",
    "    # Register the local map\n",
    "    p_reg = spatial_transform(p_pad, x)\n",
    "    # Aggregate\n",
    "    m_updated = aggregate(m, p_reg)\n",
    "\n",
    "    return m_updated\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1837bf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.14159265 3.09285051 3.14159265]\n"
     ]
    }
   ],
   "source": [
    "LOCAL_MAP_DIR  = \"/scratch/shantanu/results_23022022/occant_rgb/dump/0/Cantwell/front/bev_pred\"\n",
    "POSE_DIR  = \"/scratch/shantanu/gibson4/new/Cantwell/0/front/pose\"\n",
    "\n",
    "def register_all_observations():\n",
    "#     m = np.zeros((1,2,OUTMAP_SIZE,OUTMAP_SIZE))\n",
    "    m = np.zeros((2,OUTMAP_SIZE,OUTMAP_SIZE))\n",
    "#     m = tf.convert_to_tensor(m)\n",
    "    local_maps = os.listdir(LOCAL_MAP_DIR)\n",
    "    for local_map in local_maps[300:301]:\n",
    "        scan = local_map.split('.')[0]\n",
    "        pose = np.load(POSE_DIR+'/'+scan+'.npy',allow_pickle=True).item()\n",
    "        px,pz = pose['position'][0],pose['position'][2]\n",
    "        quat = pose['rotation']\n",
    "        yaw = quaternion.as_euler_angles(quat)[2]\n",
    "        angles = quaternion.as_euler_angles(quat)\n",
    "        \n",
    "        print(angles)\n",
    "#         x = np.array([[px,pz,yaw]])\n",
    "        x = np.array([px,pz,yaw])\n",
    "        \n",
    "#         x = tf.convert_to_tensor(x)\n",
    "#         print(x)\n",
    "        p = cv2.imread(LOCAL_MAP_DIR+'/'+local_map,-1)\n",
    "        unknown_p = (1-(p==0))\n",
    "        p_reg = np.zeros((2,LOCAL_MAP_SIZE,LOCAL_MAP_SIZE))\n",
    "        p_reg[0,:] = p\n",
    "        p_reg[1,:] = unknown_p\n",
    "#         plt.imshow(unknown_p)\n",
    "#         print(p_reg.shape)\n",
    "#         print(np.unique(p_reg))\n",
    "#         p_reg = np.array([np.moveaxis(np.array(p_reg),-1,0)])\n",
    "#         p_reg = np.moveaxis(np.array(p_reg),-1,0)\n",
    "#         p_reg = tf.convert_to_tensor(p_reg)\n",
    "#         print(p_reg)\n",
    "        m = register_map(m,p_reg,x)\n",
    "    return m\n",
    "m = register_all_observations()\n",
    "# plt.imshow(m[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
